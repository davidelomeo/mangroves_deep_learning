{"cells":[{"cell_type":"markdown","metadata":{"id":"Uv0YNSF0xtOL"},"source":["<table class=\"ee-notebook-buttons\" align=\"left\">\n","    <td><a target=\"_blank\"  href=\"https://github.com/davidelomeo/mangroves_deep_learning/blob/main/Notebook_3-Make_Predictions.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td>\n","    <td><a target=\"_blank\"  href=\"https://colab.research.google.com/github/davidelomeo/mangroves_deep_learning/blob/main/Notebook_3-Make_Predictions.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a></td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"DYLtX9Nx8So_"},"source":["# **Requirements**\n","The requirements to run this notebook are:\n","1. Have a @gmail account **->** here how to get one: https://support.google.com/accounts/answer/27441?hl=en\n","2. Have a Google Earth Engine account **->** here how to get one: https://signup.earthengine.google.com/\n","3. (*Optional* - see disclaimer below) Have a Google Coud Storage setup **->** here how to get one: https://cloud.google.com/storage *(please read Note 2 below)*\n","\n","---\n","**Note**: Google Earth Engine is a free to use online tool, but it requires authorisation from Google first. After signing up, it may take a few days before being able to access the platform.\n","\n","**Note 2**: Google Cloud Storage IS NOT a free tool. Like many other cloud services, it has different costs for different services.\n","At the time of writing of this notebook, Google offers new Cloud Storage users a 90-day free trial with some funds attached to it.\n","Please find more info at: https://cloud.google.com/free/docs/gcp-free-tier\n","\n","---\n","**Disclaimer**: Using Google Cloud storge is only optional if the user is not interested in exporting the produced classifed image to Google Earth Engine as an asset. If instead, the user is interested in producing an asset, the use of Google Cloud Storage becomes mandatory. This is because the command line that uses the Earth Engine API expects the files to be stored in Google Cloud Storage. Please see the following link for reference: https://developers.google.com/earth-engine/guides/command_line#upload"]},{"cell_type":"markdown","metadata":{"id":"y2Yo-rMK2X5f"},"source":["# **Objective**\n","\n","This Notebook has the purpose of generating an image composite of a target small geographical area and time, exporting the image as TFRecords patches to the target Google storage and make predictions and cross-validation.\n","\n","The exported patches are classified using the choes neural network. The notebook is setup to load model pre-trained in Notebook_2 (although the user may use any relevant Keras model). The classified images **must** be exported to Google Cloud Storage if the user decieds to then export the classification as a Google Earth Engine asset."]},{"cell_type":"markdown","metadata":{"id":"y7mWXWQcoT3y"},"source":["# 1. Preparing the workspace"]},{"cell_type":"markdown","metadata":{"id":"iwlnNlzCol2Q"},"source":["## Cloning the Github Repository\n","The github repository that stores the project is cloned to the workspace to allow accessing the needed packages."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1508,"status":"ok","timestamp":1629617755570,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"_YnsAHcrL5GQ","outputId":"3be6b744-ef29-4bb4-e349-e2f57c045600"},"outputs":[],"source":["github_repo = \"https://github.com/davidelomeo/mangroves_deep_learning.git\"\n","print(\"Github Repository: \", github_repo)\n","\n","!git clone \"{github_repo}\" # clone the github repository"]},{"cell_type":"markdown","metadata":{"id":"nK1HwybnourY"},"source":["## Installing the required packages\n","Although Google Colab has a pre-installed environment that contains many packages, a `requirement.txt` was provided in the GitHub repository for consistency (please see disclaimer below).\n","\n","The following code also install custom packages created specifically to facilitate the reproducibility of some key parts of the worfkflow, and hence allow the user to re-use these packages in other projects.\n","\n","---\n","**Disclaimer**: The notebook was specifically designed to work on Google Colab. The user may use the notebook on a local machine (e.g. using jupyter notebook), but mounting the Google Drive will not be possible with the method showed below. In that scenario, the user may need to use Google Cloud Storage only."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhccM8LgMGUT"},"outputs":[],"source":["# Installing requirements.txt\n","# '&> /dev/null' allows to hide the terminal output when running the command\n","!pip install -r mangroves_deep_learning/requirements.txt &> /dev/null"]},{"cell_type":"markdown","metadata":{"id":"JBXvXiRwoz6u"},"source":["## Importing the required packages\n","Here the code imports all the needed packages for this notebook.\n","\n","**Note**: it is necessary to authenticate Google Drive, Google Cloud Storage and Google Earth Engine to use the entire notebook. Make sure to have previoulsy created the necessary accounts.\n","\n","Alternatively, the user can only authenticate Google Drive and Google Earth Engine, but will not be able to generate assets of the predicted images.\n","\n","---\n","As the cell below is executed, both Google Drive and Google Earth Engine will require authentication. Please select the links that will appear below the code - this will open a new tab in the browser - login with the desired gmail account, allow Google to access the application and copy the key that will show on screen inside the box below."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65964,"status":"ok","timestamp":1629617839583,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"WNy0dJwYMHyO","outputId":"50917c6a-54db-4b0a-f1a3-a721eec17c02"},"outputs":[],"source":["import ee\n","import geemap\n","import time\n","import json\n","import subprocess\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","from pprint import pprint\n","from tensorflow import keras\n","\n","# These are custom packages. Please see the README in the repo for details.\n","import eeCustomTools as ct\n","import eeCustomDeepTools as cdt\n","\n","from google.colab import auth, drive\n","# Authorising Google Colab notebook to access the target Google Drive and mount it\n","drive.mount('/content/drive')\n","\n","# Authorising Google Colab to access the Google Earth Engine account\n","try:\n","    ee.Initialize()\n","except Exception as e:\n","    ee.Authenticate()\n","    ee.Initialize()\n","\n","# Outputting plots in the notebook\n","%pylab inline\n","# Loading tensorboard notebook extensions\n","%load_ext tensorboard"]},{"cell_type":"markdown","metadata":{"id":"5eqrb2NPQN_x"},"source":["----> Only Run the next cell if wanting to export the classified patches to Google Earth Engine, and therefore, through storing the exported patches in Google Cloud Storage or to load pre-saved patches from Google Cloud Storage.\n","\n","---\n","Please authenticate Google Cloud Storage as done above with Google Drive and Earth Engine"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_mptem5QMtW"},"outputs":[],"source":["# Authorising Google Colab notebook to access the target Google Cloud account\n","auth.authenticate_user()"]},{"cell_type":"markdown","metadata":{"id":"uaxxYn1Qp0o5"},"source":["# 2. Prepare patches that need classification (optional)\n","This section needs to be run only if the user has not already exported patches for prediction from elsewhere.\n","\n","**Note**: As mentioned above, if the user is interested in exporting the classification image to Google Earth Engine, then it is **mandatory** to use Google Cloud Storage to store the patches. "]},{"cell_type":"markdown","metadata":{"id":"HVMAwHrzPbj_"},"source":["## Load images of a target year"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_wqz-6A-ENyu"},"outputs":[],"source":["# Loading a pre-defined Southeast Asia area of interest. This variable is not\n","# necessary but useful for delimiting the geographical area to Southeas Asia.\n","ROI = ee.FeatureCollection('users/davidelomeo/acse9_final_project/SEA')\n","\n","# Setting the start and end dates\n","start_date = ee.Date.fromYMD(2018, 1, 1)\n","end_date = ee.Date.fromYMD(2018, 12, 31)\n","\n","# Loading the images for the selected period and bouding them to the target ROI.\n","# The images are pre-filtered to only get those with maximum 30% of cloud cover\n","# to reduce the cloud masking effect on the images.\n","image_collection = ee.ImageCollection('COPERNICUS/S2') \\\n","                     .filterDate(start_date, end_date) \\\n","                     .filterBounds(ROI) \\\n","                     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n","                     .map(ct.mask_sentinel_clouds)\n","\n","# Getting spectral indices for the median image and clipping to ROI. The median\n","# pixel value was preferred from the mean to avoid potential skeweness in the \n","# pixels values distribution\n","median_image = ct.sentinel2_spectral_indices(\n","    image_collection.median()).clip(ROI)\n","\n","# Creating a separate image for RGB visualisation\n","rgb_image = median_image.select(['B2', 'B3', 'B4'])\n","\n","# Selecting the bands needed for the classification\n","bands = [\n","    'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', \n","    'NDVI', 'NDWI', 'MNDWI', 'NDSI', 'NDMI', 'EVI', 'EVI2', 'GOSAVI', 'SAVI'\n","]\n","\n","# Adding the computed bands to the median image\n","median_image = median_image.select(bands)"]},{"cell_type":"markdown","metadata":{"id":"cD_TKJgQFmxE"},"source":["## Classify the image\n","Classification of the image selected above using pre-defined points around Southeas Asia. For more in depth details about the section below, please refer to Notebook_1 in the GitHub Repository.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6iOH6zwSBptt"},"outputs":[],"source":["# Manually classified markers\n","classes_2016 = ee.FeatureCollection(\n","    'users/davidelomeo/acse9_final_project/mangrove_custom_classes_2016')\n","\n","class_columns_name = 'Class'\n","\n","# Separating clouds classes and creating small 5 meters buffers. This was done\n","# because clouds can be seen as very small from the satellite and could not risk\n","# to capture any of the pixels that did not belong to clouds\n","clouds = classes_2016.filter(\n","    ee.Filter.eq(class_columns_name, 6)).map(ct.buffer_size(5))\n","\n","# Creating 50m buffers around no-cloud classes points\n","no_clouds = classes_2016.filter(\n","    ee.Filter.neq(class_columns_name, 6)).map(ct.buffer_size(50))\n","\n","# Merging clouds with no_clouds classes and remapping classes Clouds, Urban\n","# and Ground so that they are classified as being the same (i.e., other)\n","region_of_interest = no_clouds.merge(clouds).remap([0, 1, 2, 3, 4, 5, 6, 7, 8],\n","                                                   [0, 1, 2, 3, 4, 5, 6, 6, 6],\n","                                                   class_columns_name)\n","\n","# segmenting the image using Simple Non-Iterative Clustering\n","segmented_image = ct.segment_image(median_image, bands)\n","\n","# Reducing the segmented image to the input collection\n","training = segmented_image.sampleRegions(\n","  collection=region_of_interest, \n","  properties=[class_columns_name], \n","  scale=10)\n","\n","# Initialising random splitting adding a column of pseudo-random \n","# numbers between 0 and 1 to the collection\n","random_column = training.randomColumn('random')\n","\n","# Splitting the dataset into training and test datasets using the custom\n","# percentage.\n","train_dataset = random_column.filter(ee.Filter.lt('random', 0.7))\n","test_dataset = random_column.filter(ee.Filter.gte('random', 0.7))\n","\n","# Generating the classifier using random forest\n","classifier = ee.Classifier.smileRandomForest(\n","  numberOfTrees=200,\n",").train(\n","  features=train_dataset,\n","  classProperty=class_columns_name,\n","  inputProperties=median_image.bandNames())\n","\n","# Classifying the target median image\n","classified_image = median_image.classify(classifier).rename('classes')"]},{"cell_type":"markdown","metadata":{"id":"gAFURSbLPVSz"},"source":["## Draw an area of interest\n","Neither Geemap (the visualisation package used in this notebook) nor Folium provide drawing capabilities for satellite imagery visualisation on Google Colab.\n","\n","The only way to actually 'draw' an area of interest (e.g. defining a square) using Geemap interactive tool is to open the notebook with Jupyter Notebook on a local machine. \n","\n","Instead, the approach used here is to click on a spot on the map, copy the Latitude and Longitude, create a buffer of custom size around that point and generate a square around the buffer.\n","\n","Alternatively, the user could use the `ee.Geometry.Rectancgle` function, but it would need to know the coordinates of 4 points on the map. to generate the rectangle."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":952},"executionInfo":{"elapsed":1821,"status":"ok","timestamp":1629618449191,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"ghlQC7uvE-TK","outputId":"f92bbfc3-3e11-4856-ae8e-262388e8024a"},"outputs":[],"source":["# Please change the poi below to an area of interest\n","# -------------------\n","poi = {\n","'Latitude': 18.8907,\n","'Longitude': 94.1099\n","}\n","\n","# Creating a buffer of custom size around the point (metres by default)\n","xy = ee.Geometry.Point(poi['Longitude'], poi['Latitude']).buffer(5000)\n","\n","# Bounding the buffer with a square\n","poi = xy.bounds()\n","# -------------------\n","\n","# Setting True Colour Composite visualisation parameters\n","RGB = {\n","  'min': 0.0,\n","  'max': 0.3,\n","  'bands': ['B4', 'B3', 'B2']}\n","\n","# Generating the map and adding layers for every feature that needs output\n","Map = geemap.Map(center=(7.8, -261), zoom=8, lite_mode=False)\n","Map.centerObject(xy, 13)\n","Map.addLayer(rgb_image, RGB, 'RGB Image')\n","Map.addLayer(poi, {'color':'red'}, 'POI', opacity=0.5)\n","\n","Map"]},{"cell_type":"markdown","metadata":{"id":"0BPnNcXTEnfT"},"source":["## Visualise the classified image within the point of interest (Optional)\n","Visualising the point of interest with the classified pixels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":952},"executionInfo":{"elapsed":95730,"status":"ok","timestamp":1629617978191,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"LpgvHuilEnLM","outputId":"34f251d0-40d7-4d47-9468-49ccfa0fdb9b"},"outputs":[],"source":["# Creating colour palette for the target classes\n","legend_dict = {\n","    'Delta': '80D604', \n","    'Estuary': '01BD7C', \n","    'Lagoon': '36DFFF', \n","    'OpenCoast': 'DEFF00', \n","    'Water': '0050D5', \n","    'NonMangroves': '106703', \n","    'Other': 'B06F03'\n","}\n","\n","Map = geemap.Map(center=(7.8, -261), zoom=8, lite_mode=False)\n","Map.centerObject(xy, 13)\n","Map.addLayer(classified_image, \n","             {'min': 0, 'max': 6, \n","              'palette': [v for v in legend_dict.values()]},\n","              'Classification 2016')\n","Map.add_legend(title='Legend', legend_dict=legend_dict)\n","Map.addLayer(poi, {'color':'grey'}, 'POI', opacity=0.5)\n","Map"]},{"cell_type":"markdown","metadata":{"id":"Dv9JXJJtqYyN"},"source":["## Export pacthes within the Area of Interest to Google Cloud Storage\n","The median image and the classes here are exported as separate TFRecords dataset due to the classes not being needed for prediction purposes and only used for cross-validation with the random forest classifier.\n","\n","The exports are done separately due to the Earth Engine API giving an error when running multiple simultaneous exports in the same cell."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZxKpZTQldRFt"},"outputs":[],"source":["# user-defined parameters: please modify the following variables with your own\n","# Google Cloud Storage bucket and folders names\n","# ------------------------------------------------------------------------\n","parent_folder = 'prediction_patch/'\n","child_folder = '2016'\n","bucket = 'mangroves_classification_bucket'\n","scale = 10\n","pixels = 256"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VP6JSQtNKJB"},"outputs":[],"source":["# Specify patch and file dimensions.\n","export_options = {\n","  'patchDimensions': [pixels, pixels],\n","  'compressed': True,\n","}\n","\n","# Exporting patches to Google Cloud Storage\n","image_task = ee.batch.Export.image.toCloudStorage(\n","  image = median_image,\n","  description = 'Patches_Export',\n","  fileNamePrefix = parent_folder+'_img_'+child_folder,\n","  bucket = bucket,\n","  scale = scale,\n","  maxPixels = 3784216672400,\n","  fileFormat = 'TFRecord',\n","  region = poi,\n","  formatOptions = export_options,\n",")\n","\n","# Starting the export task\n","image_task.start()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XB8uuK2lw_nK"},"outputs":[],"source":["# Specify patch and file dimensions.\n","export_options = {\n","  'patchDimensions': [pixels, pixels],\n","  'compressed': True,\n","}\n","\n","# Exporting patches to Google Cloud Storage\n","classes_task = ee.batch.Export.image.toCloudStorage(\n","  image = classified_image,\n","  description = 'Patches_Export',\n","  fileNamePrefix = parent_folder + 'classes_' + child_folder,\n","  bucket = bucket,\n","  scale = scale,\n","  maxPixels = 3784216672400,\n","  fileFormat = 'TFRecord',\n","  region = poi,\n","  formatOptions = export_options,\n",")\n","\n","# Starting the export task\n","classes_task.start()"]},{"cell_type":"markdown","metadata":{"id":"oPo9C0QIbMQL"},"source":["### Monitoring export status (optional)\n","If running this cell, the code will run as long as the export tasks run"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":181930,"status":"ok","timestamp":1629618657542,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"1hJRawLhPEvv","outputId":"dd5913a8-65f2-40cf-af5b-34c28d9d6690"},"outputs":[],"source":["# Checking the status of the export\n","while (image_task.active()) | (classes_task.active()):\n","  print('Running id: {}.'.format(image_task.id))\n","  print('Running id: {}.'.format(classes_task.id))\n","  time.sleep(60)"]},{"cell_type":"markdown","metadata":{"id":"G2qg05ehqdsL"},"source":["# 3. Loading patches for predictions\n","This section uses the pacthes exported above or imported by the user from a target Google Cloud Storage folder to make predictions using the target Keras model."]},{"cell_type":"markdown","metadata":{"id":"qQiH8K2WrORK"},"source":["### Checking GPU availability (Optional)\n","Checking if a GPU is available. This task is useful especially if the user has a basc Google Colab account, for which the GPU availability is time-restricted.\n","\n","Having a GPU available for predictions is not essential becuase the CPU can handle the task just fine. Nevertheless, the prediction may be particularly slow if the number of pacthes is really large."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3798,"status":"ok","timestamp":1629617983090,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"0zXESGBmsfwe","outputId":"ae9dbebb-630d-40f1-eb62-194c98fc7084"},"outputs":[],"source":["# Checking the presence of a GPU\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"markdown","metadata":{"id":"sun-24I_Pzr0"},"source":["## Loading TFRecords pacthes from Google Cloud Storage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4182,"status":"ok","timestamp":1629618672506,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"N_dhCy3XP3e9","outputId":"bdc80215-f706-49f6-d33e-44c1788fba86"},"outputs":[],"source":["# user-defined parameters: please modify the following variables with your own\n","# Google Cloud Storage bucket, folders and files names\n","# ------------------------------------------------------------------------\n","parent_folder = 'prediction_patch'\n","pred_prefix = 'img_2016'\n","class_prefix = 'classes_2016'\n","bucket = 'mangroves_classification_bucket'\n","\n","# Accessing the Google Cloud Storage Path\n","path_to_pred_patch = !gsutil ls 'gs://'{bucket}'/'{parent_folder}'/'\n","\n","# Getting the list of the records and the mixer\n","pred_info = cdt.GetFilesInfo(storage='gstorage')\n","\n","# getting the mixer for the images\n","pred_patch_file_list, pred_json = pred_info.get_files(path_to_pred_patch, pred_prefix)\n","pred_mixer = pred_info.get_mixer(pred_json)\n","\n","# getting the mixer for the classes\n","class_file_list, class_json = pred_info.get_files(path_to_pred_patch, class_prefix)\n","class_mixer = pred_info.get_mixer(class_json)\n","\n","pprint(pred_mixer)\n","pprint(class_mixer)"]},{"cell_type":"markdown","metadata":{"id":"z7pHgiVOSQdA"},"source":["## Loading TFRecords classes from Google Cloud Storage"]},{"cell_type":"markdown","metadata":{"id":"Fk6zIGHkQHpX"},"source":["## Prepare data for prediction\n","Prepare the TFRecords imported above for predictions by converting them to a batch dataset ready for the neural network.\n","\n","**Note**: The bands selected need to be the same as those used when training the model (here bands 1 to 12)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1629618672863,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"zxvbfOUobsCC","outputId":"93d0729f-6ea4-4890-bc4d-829109b1aec1"},"outputs":[],"source":["# Repeating the bands here just in case Section 2 was not ran\n","\n","bands = [\n","    'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', \n","    'NDVI', 'NDWI', 'MNDWI', 'NDSI', 'NDMI', 'EVI', 'EVI2', 'GOSAVI', 'SAVI'\n","]\n","\n","# Please modify the variable within the following lines to set the bands of\n","# interests for the model\n","# -------------------------------------------------------------------------\n","bands_of_interest = bands[:12]\n","# -------------------------------------------------------------------------\n","\n","# Generating the batch with the patches ready for prediction\n","predict_db = cdt.prepare_prediction_dataset(\n","    pred_patch_file_list, pred_mixer['patchDimensions'], bands_of_interest)\n","\n","pprint(predict_db)"]},{"cell_type":"markdown","metadata":{"id":"j77Bt3Tds4Xi"},"source":["## Prepare classes for cross-validation\n","Prepare the TFRecord containing the classification values to facilitate the cross-validation task with the predictions generated in the keras models below.\n","\n","**Note**: the next cell converts the input classes TensorFlow dataset into a list of arrays. The action is particularly consuming, hence, please respect the advice of this notebook to only use small areas for predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":671,"status":"ok","timestamp":1629618680467,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"RPgAD3fuQkRF","outputId":"5e7be6d2-97d5-4e9e-c679-1316f8664c50"},"outputs":[],"source":["classes_db = cdt.prepare_prediction_classes(\n","    class_file_list, class_mixer['patchDimensions'], ['classes'])\n","\n","pprint(classes_db)\n","\n","classes_db = list(classes_db.as_numpy_iterator())"]},{"cell_type":"markdown","metadata":{"id":"1Iq75CzMgkyO"},"source":["## Plot the history of the target model\n","Plot the loss, accuracy, cross entropy, precision, recall and f1-score of the target model to guide the decision to select the 'best' model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":916},"executionInfo":{"elapsed":2001,"status":"ok","timestamp":1629457690312,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"yDtGQiL8vhiE","outputId":"27cf7b19-22eb-42e0-d4c4-6dce911d14d8"},"outputs":[],"source":["# loading the json fil that contains the name and the path of the exported paches\n","model_history = '/content/drive/MyDrive/UNet_models/UNet_model_sig_foc_crossentropy_9/history.js'\n","with open(model_history) as j:\n","  full_model_hist = json.load(j)\n","\n","fig, ax = plt.subplots(3, 2, figsize=(12, 12))\n","fig.tight_layout(w_pad=3, h_pad=4)\n","\n","# Plotting history for accuracy\n","ax[0, 0].plot(full_model_hist['cat_acc'])\n","ax[0, 0].plot(full_model_hist['val_cat_acc'])\n","ax[0, 0].set_title('Model Accuracy')\n","ax[0, 0].set_ylabel('accuracy')\n","ax[0, 0].set_xlabel('epoch')\n","ax[0, 0].legend(['train', 'validation'], loc='upper left')\n","\n","# Plotting history for categorical crossentropy\n","ax[0, 1].plot(full_model_hist['cat_xntrp'])\n","ax[0, 1].plot(full_model_hist['val_cat_xntrp'])\n","ax[0, 1].set_title('Model Crossentropy')\n","ax[0, 1].set_ylabel('categorical crossentropy')\n","ax[0, 1].set_xlabel('epoch')\n","ax[0, 1].legend(['train', 'validation'], loc='upper left')\n","\n","# Plotting history for loss\n","ax[2, 1].plot(full_model_hist['loss'])\n","ax[2, 1].plot(full_model_hist['val_loss'])\n","ax[2, 1].set_title('Model Loss')\n","ax[2, 1].set_ylabel('loss')\n","ax[2, 1].set_xlabel('epoch')\n","ax[2, 1].legend(['train', 'validation'], loc='upper left')\n","\n","# Plotting history for f1 score\n","ax[2, 0].plot(full_model_hist['f1_score'])\n","ax[2, 0].plot(full_model_hist['val_f1_score'])\n","ax[2, 0].set_title('Model F1 Score')\n","ax[2, 0].set_ylabel('f1 score')\n","ax[2, 0].set_xlabel('epoch')\n","ax[2, 0].legend(['train', 'validation'], loc='upper left')\n","\n","# Plotting history for precision\n","ax[1, 0].plot(full_model_hist['prec'])\n","ax[1, 0].plot(full_model_hist['val_prec'])\n","ax[1, 0].set_title('Model Precision')\n","ax[1, 0].set_ylabel('precision')\n","ax[1, 0].set_xlabel('epoch')\n","ax[1, 0].legend(['train', 'validation'], loc='upper left')\n","\n","# Plotting history for recall\n","ax[1, 1].plot(full_model_hist['rec'])\n","ax[1, 1].plot(full_model_hist['val_rec'])\n","ax[1, 1].set_title('Model Recall')\n","ax[1, 1].set_ylabel('recall')\n","ax[1, 1].set_xlabel('epoch')\n","ax[1, 1].legend(['train', 'validation'], loc='upper left')"]},{"cell_type":"markdown","metadata":{"id":"-XXBWuWfQL3o"},"source":["## Load target keras model and make predictions\n","**Important Note**: It is advisable to only use this method of prediction if the target pacthes dataset is not too large. Here, the target data is made up of only 12 patches and it is there only for demonstrative purposes. It is very likely that Google Colab's memory allocation exceeds if the user tries to predict too many patches at once."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cxr97u0y-5Ze"},"outputs":[],"source":["folder = '/content/drive/MyDrive/UNet_models/UNet_model_sig_foc_crossentropy_9/'\n","model = folder + 'epochs:006.h5'\n","logs = folder + 'logs'\n","loaded_model = keras.models.load_model(model)\n","predictions = loaded_model.predict(predict_db)\n","\n","# get total patches number\n","num_patches = pred_mixer['totalPatches']\n","\n","# Getting the most likely class for each pixel\n","predicted_classes = [tf.argmax(predictions[i], 2).numpy() for i in range(num_patches)]#.T.argmax(0)\n","\n","# Converting the input data into a numpy array (this take is very costly, so it\n","# is advisable to only use small patches number)\n","records = list(predict_db.as_numpy_iterator())\n","img = [records[i][0] for i in range(num_patches)]"]},{"cell_type":"markdown","metadata":{"id":"YYINQcWMQZ1F"},"source":["## Visualise predicted patches (optional)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPxLBgR9ma0k"},"outputs":[],"source":["# Keep the number of columns an even number to allow the images of patches to \n","# be flanked by their mask. Please change these parameters according to your needs\n","rows = 3\n","cols = 8\n","\n","# Here the Red, Yellow and Blue bands are in position 5, 4, 3 due to the bands\n","# distribution in the feature_dictionary outputted above. These will need to\n","# be changed if the user uses a different number of bands\n","if len(bands_of_interest) == 3:\n","  rgb_image = [np.stack([img[i][:,:,2],\n","                         img[i][:,:,1],\n","                         img[i][:,:,0]], axis=2) for i in range(num_patches)]\n","\n","# Please modify the numbers within the square brackets to reflect the wanted\n","# bands for visualisation\n","else:\n","  rgb_image = [np.stack([img[i][:,:,5],\n","                         img[i][:,:,4],\n","                         img[i][:,:,3]], axis=2) for i in range(num_patches)]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":538,"output_embedded_package_id":"1DHlRKBA6JCMsQaxjBdbs_bcKBhtdCwBO"},"executionInfo":{"elapsed":6869,"status":"ok","timestamp":1629618084156,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"x-3LX2-bWqwv","outputId":"6c0c0fc2-338a-482b-f8f2-261efa399d19"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["# Setting the plot size\n","fig, ax = plt.subplots(rows, cols, figsize=(36, 12))\n","fig.tight_layout(w_pad=1, h_pad=1)\n","\n","# Plotting the target patches and the relative masks\n","count = 0\n","for i in range(rows):\n","  idx = count\n","  for j in range(cols):\n","    if j % 2 == 0:\n","      ax[i, j].imshow(rgb_image[idx]*5)\n","    else:\n","      ax[i, j].imshow(predicted_classes[idx])\n","      idx += 1\n","  count += int((cols/2))"]},{"cell_type":"markdown","metadata":{"id":"T6dRRZkQG_64"},"source":["# 4. Cross-validate predictions with GEE classifier\n","The predictions computed above are compared to the classification made in Google Earth Engine using a traditional classifier"]},{"cell_type":"markdown","metadata":{"id":"S6-wxl_Ur4az"},"source":["## Generating a confusion matrix for each of the patches"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYszwQi8IyDR"},"outputs":[],"source":["conf_matrix = [tf.math.confusion_matrix(labels=classes_db[i].flatten(),\n","                                        predictions=predicted_classes[i].flatten()) for i in range(num_patches)]"]},{"cell_type":"markdown","metadata":{"id":"Hxabq2l3sLxR"},"source":["## Computing User and Producer accuracies for the entire scene"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235,"status":"ok","timestamp":1629618107131,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"dvP3exACRxCZ","outputId":"d6614c3e-f0c5-4904-af5d-f47d0ba40f16"},"outputs":[],"source":["# Generating a matrix of zeros to store the summations\n","sum_conf_matrices = np.zeros((conf_matrix[0].shape))\n","\n","# Summing the confusion matrices\n","for matrix in conf_matrix:\n","  sum_conf_matrices += matrix\n","\n","# List to store the values\n","sum_tot_user = []\n","sum_tot_prod = []\n","sum_user_acc = []\n","sum_prod_acc = []\n","\n","# Computing the sum of values in each row and column\n","for k in range(conf_matrix[0].shape[0]):\n","  sum_tot_user.append(sum(sum_conf_matrices[k]))\n","  sum_tot_prod.append(sum([i[k] for i in sum_conf_matrices]))\n","\n","# Computing the User and producer accuracies\n","for j in range(conf_matrix[0].shape[0]):\n","  sum_user_acc.append(round(\n","      float(sum_conf_matrices[j][j]/sum_tot_user[j]*100), 2))\n","  sum_prod_acc.append(round(\n","      float(sum_conf_matrices[j][j]/sum_tot_prod[j]*100), 2))\n","\n","# checking if the summations are correct (hence, match)\n","assert sum(sum_tot_user) == sum(sum_tot_prod)\n","\n","# output the values (Note: nans are to be considered zeros)\n","print('User Accuracies:', sum_user_acc)\n","print('\\nProducer Accuracies:', sum_prod_acc)\n","print('\\n\\nSum Confusion Matrices:')\n","pprint(sum_conf_matrices)\n"]},{"cell_type":"markdown","metadata":{"id":"Y1fV7cg2r9XZ"},"source":["## Computing User and Producer accuracies for each patch (Optional)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RRKwj-U8Lw7C"},"outputs":[],"source":["# Generating lists to store the values\n","tot_user = [[] for i in range(num_patches)]\n","tot_prod = [[] for i in range(num_patches)]\n","user_acc = [[] for i in range(num_patches)]\n","prod_acc = [[] for i in range(num_patches)]\n","\n","# Computing the sum of values in each row and column\n","for j in range(num_patches):\n","  for k in range(conf_matrix[0].shape[0]):\n","    tot_user[j].append(sum(conf_matrix[j][k]))\n","    tot_prod[j].append(sum([i[k] for i in conf_matrix[j]]))\n","\n","# Computing the User and producer accuracies\n","for i in range(num_patches):\n","  for j in range(conf_matrix[0].shape[0]):\n","    user_acc[i].append(round(float(conf_matrix[i][j][j]/tot_user[i][j]*100), 2))\n","    prod_acc[i].append(round(float(conf_matrix[i][j][j]/tot_prod[i][j]*100), 2))\n","\n","# checking if the summations are correct (hence, match)\n","assert sum(tot_user) == sum(tot_prod)\n","\n","# output the values (Note: nans are to be considered zeros)\n","pprint(user_acc)\n","print('')\n","pprint(prod_acc)"]},{"cell_type":"markdown","metadata":{"id":"Ix7kvmovQfgx"},"source":["# 5. Prepare predictions for export to Earth Engine\n","For this task the user **must** provide a Google Cloud Storage path. As explained above, Google Earth Engine can only convert TFRecords to assets if these are stored in Google Cloud Storage (Google Drive will not work for this task).\n","\n","Please look at Google's documentation if in doubt: https://developers.google.com/earth-engine/guides/command_line#upload\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":751,"status":"ok","timestamp":1629619432669,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"28n_PuMLSBOB","outputId":"884c39bb-0cd7-4df3-d3f7-4636a8b54cb7"},"outputs":[],"source":["# user-defined parameters: please modify the following variables with your own\n","# Google Cloud Storage bucket and folders names\n","# ------------------------------------------------------------------------\n","predictions_folder = 'predicted_images'\n","predicted_image = 'UNet_sig_foc_crossentropy_9_006_img_2016'\n","out_predicted = 'gs://' + bucket + '/' + predictions_folder + '/' + predicted_image + '.TFRecord'\n","\n","# Initiate the TFRecord writer on the target Google Cloud Storage \n","writer = tf.io.TFRecordWriter(out_predicted)\n","\n","# Writing predicted features to the target TFRecord. Since the predictions are in\n","# the order of the exported data, the patches will also follow the right ordering\n","patch_size = pred_mixer['patchDimensions'][0]\n","curPatch = 1\n","for  prediction in predictions:\n","  # Obtaining the most likely class for each pixel using argax()\n","  patch = prediction.squeeze().T.argmax(0).flatten().tolist()\n","\n","  # ensuring that the predictions patch matches the expected length\n","  if (len(patch) == patch_size * patch_size):\n","    print('Done with patch ' + str(curPatch) + '...')  \n","  \n","    # Creating an Example, which will be the patch visualised in Earth Engine\n","    example = tf.train.Example(\n","      features = tf.train.Features(\n","        feature = {\n","          'prediction': tf.train.Feature(\n","              float_list = tf.train.FloatList(\n","                  value = patch))\n","        }\n","      )\n","    )\n","\n","    # Converting the saved TFRecords to binary strings as expected by Earth Engine\n","    writer.write(example.SerializeToString())    \n","    curPatch += 1 \n","\n","# Finishing the writing task\n","writer.close()"]},{"cell_type":"markdown","metadata":{"id":"QoKaauqUQpgz"},"source":["## Setup asset ID\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1629619435902,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"V8AJoT3vrBAb","outputId":"1809357b-7a11-4723-9de2-db8434e55130"},"outputs":[],"source":["# user-defined parameters: please modify the following variables with your own\n","# Earth Engine username and wanted assed ID\n","# ------------------------------------------------------------------------\n","username = 'davidelomeo'\n","outputAssetID = 'users/' + username + '/' + predicted_image\n","print('Writing to ' + outputAssetID)"]},{"cell_type":"markdown","metadata":{"id":"LlgdKgNuQ0PY"},"source":["## Generate Eath Engine Asset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xswmZIRUOW1P"},"outputs":[],"source":["# Uploading the records to Earth Egnine as an asset. This action may take a\n","# while if the predicted area is large.\n","!earthengine upload image --asset_id={outputAssetID} {out_predicted} {pred_json}"]},{"cell_type":"markdown","metadata":{"id":"koysDeukQ5MN"},"source":["# 5. Visualise predicted patches on Earth Engine\n","Loading the asset exported to Earth Engine and output it using the original classification palette used in Notebook 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IIWBkhmymDcF"},"outputs":[],"source":["# Loading a pre-defined Southeast Asia area of interest. This variable is not\n","# necessary but useful for delimiting the geographical area to Southeas Asia.\n","ROI = ee.FeatureCollection('users/davidelomeo/acse9_final_project/SEA')\n","\n","# Setting the start and end dates\n","start_date = ee.Date.fromYMD(2016,1,1)\n","end_date = ee.Date.fromYMD(2016, 12,31)\n","\n","# Loading the images for the selected period and bouding them to the target ROI.\n","# The images are pre-filtered to only get those with maximum 30% of cloud cover\n","# to reduce the cloud masking effect on the images.\n","image_collection = ee.ImageCollection('COPERNICUS/S2') \\\n","                     .filterDate(start_date, end_date) \\\n","                     .filterBounds(ROI) \\\n","                     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n","                     .map(ct.mask_sentinel_clouds)\n","\n","# Getting spectral indices for the median image and clipping to ROI. The median\n","# pixel value was preferred from the mean to avoid potential skeweness in the \n","# pixels values distribution\n","median_image = image_collection.median().clip(ROI)\n","\n","# Creating a separate image for RGB visualisation\n","rgb_image = median_image.select(['B2', 'B3', 'B4'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":952},"executionInfo":{"elapsed":1949,"status":"ok","timestamp":1629619367338,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"YdvvQ3PHUKCR","outputId":"3151ef69-6148-43b8-88b4-567c965cfaab"},"outputs":[],"source":["# Loading the asset previously exported to Earth Engine.\n","# Please change the path and name of the asset accordignly.\n","probs_image = ee.Image('users/davidelomeo/UNet_sig_foc_crossentropy_9_006_img_2016')\n","\n","RGB = {\n","  'min': 0.0,\n","  'max': 0.3,\n","  'bands': ['B4', 'B3', 'B2']}\n","\n","# Creating colour palette for the target classes\n","legend_dict = {\n","    'Delta': '80D604', \n","    'Estuary': '01BD7C', \n","    'Lagoon': '36DFFF', \n","    'OpenCoast': 'DEFF00', \n","    'Water': '0050D5', \n","    'NonMangroves': '106703', \n","    'Other': 'B06F03'\n","}\n","\n","Map = geemap.Map()\n","Map.centerObject(probs_image, 14)\n","Map.addLayer(rgb_image, RGB, 'RGB Image')\n","Map.addLayer(probs_image, \n","             {'min': 0, 'max': 6, \n","              'palette': [v for v in legend_dict.values()]},\n","              'Classification 2016', opacity=0.5)\n","Map.add_legend(title='Legend', legend_dict=legend_dict)\n","Map"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNru36VaKh57V/Hffli0Pbz","collapsed_sections":[],"name":"Notebook_3-Make_Predictions.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
