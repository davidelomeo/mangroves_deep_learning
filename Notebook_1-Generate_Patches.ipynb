{"cells":[{"cell_type":"markdown","id":"52da8af6","metadata":{"id":"52da8af6"},"source":["<table class=\"ee-notebook-buttons\" align=\"left\">\n","    <td><a target=\"_blank\"  href=\"https://github.com/davidelomeo/mangroves_deep_learning/blob/main/Notebook_1-Generate_Patches.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td>\n","    <td><a target=\"_blank\"  href=\"https://colab.research.google.com/github/davidelomeo/mangroves_deep_learning/blob/main/Notebook_1-Generate_Patches.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a></td>\n","</table>"]},{"cell_type":"markdown","id":"ROoijd456q-G","metadata":{"id":"ROoijd456q-G"},"source":["# **Requirements**\n","The requirements to run this notebook are:\n","1. Have a @gmail account **->** here how to get one: https://support.google.com/accounts/answer/27441?hl=en\n","2. Have a Google Earth Engine account **->** here how to get one: https://signup.earthengine.google.com/\n","3. (Optional) Have a Google Coud Storage setup **->** here how to get one: https://cloud.google.com/storage *(please read Note 2 below)*\n","\n","---\n","**Note**: Google Earth Engine is a free to use online tool, but it requires authorisation from Google first. After signing up, it may take a few days before being able to access the platform.\n","\n","**Note 2**: Google Cloud Storage IS NOT a free tool. Like many other cloud services, it has different costs for different services. <br/>\n","At the time of writing of this notebook, Google offers new Cloud Storage users a 90-day free trial with some funds attached to it.<br/>\n","Please find more info at: https://cloud.google.com/free/docs/gcp-free-tier <br/>\n","\n","---\n","**Disclaimer**: Using Google Cloud storge is optional to run this notebook, but be warned that depending on the size of the geographical area that you exoprt as pacthes, and hence the number of patches exported, the free 15GB offered by Google in Google Drive may not be enough."]},{"cell_type":"markdown","id":"uEq4vSRU0Cry","metadata":{"id":"uEq4vSRU0Cry"},"source":["# **Objective**\n","\n","This Notebook has the purpose of generating image composites of a target geographical area and time period, classify the image using the traditional  machine learning classifier Random Forest, and export the classified image as TFRecords patches to the target Google storage.\n","\n","Exporting multi-bands, classified images within a target area of ineterest as patches of user-defined sizes is a key step to later feed satellite imagery to deep convolutional neural networks for training."]},{"cell_type":"markdown","id":"wVOAtstvxqXR","metadata":{"id":"wVOAtstvxqXR"},"source":["# 1. Preparing the workspace"]},{"cell_type":"markdown","id":"NhA0GcBmx2-r","metadata":{"id":"NhA0GcBmx2-r"},"source":["## Cloning the Github Repository\n","The github repository that stores the project is cloned to the workspace to allow accessing the needed packages."]},{"cell_type":"code","execution_count":null,"id":"QGHqEROLRKIF","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1655,"status":"ok","timestamp":1629653610222,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"QGHqEROLRKIF","outputId":"282253b2-c87a-40ff-d882-822a2ef355e4"},"outputs":[],"source":["github_repo = \"https://github.com/davidelomeo/mangroves_deep_learning.git\"\n","print(\"Github Repository: \", github_repo)\n","\n","!git clone \"{github_repo}\" # clone the github repository"]},{"cell_type":"markdown","id":"f_NcLCGIx54r","metadata":{"id":"f_NcLCGIx54r"},"source":["## Installing the required packages\n","Although Google Colab has a pre-installed environment that contains many packages, a `requirement.txt` was provided in the GitHub repository for consistency (please see disclaimer below).\n","\n","The following code also install custom packages created specifically to facilitate the reproducibility of some key parts of the worfkflow, and hence allow the user to re-use these packages in other projects.\n","\n","---\n","**Disclaimer**: The notebook was specifically designed to work on Google Colab. The user may use the notebook on a local machine (e.g. using jupyter notebook), but mounting the Google Drive will not be possible with the method showed below. In that scenario, the user may need to use Google Cloud Storagae only."]},{"cell_type":"code","execution_count":2,"id":"HyT2hTPxRaot","metadata":{"executionInfo":{"elapsed":19289,"status":"ok","timestamp":1629653629506,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"HyT2hTPxRaot"},"outputs":[],"source":["# Installing requirements.txt\n","# '&> /dev/null' allows to hide the terminal output when running the command\n","!pip install -r mangroves_deep_learning/requirements.txt &> /dev/null"]},{"cell_type":"markdown","id":"hM5NMhT4yBSX","metadata":{"id":"hM5NMhT4yBSX"},"source":["## Importing the required packages\n","Here the code imports all the needed packages for this notebook.\n","\n","**Note**: it is necessary to authenticate Google Drive and Earth Engine to use the notebook. Make sure to have previoulsy created the necessary accounts."]},{"cell_type":"code","execution_count":null,"id":"66a34ac6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29530,"status":"ok","timestamp":1629653659031,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"66a34ac6","outputId":"bb8771d0-e093-4e18-c4e1-eca7d9c77c81"},"outputs":[],"source":["import ee\n","import geemap\n","import time\n","import json\n","from pprint import pprint\n","\n","# This is a custom package. Please see the README in the repo for details.\n","import eeCustomTools as ct\n","\n","# Authorising Google Colab notebook to access the target\n","# Google Drive and mount it\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Checking if Earth Engine is already authenticated and\n","# starts the authentication process if it is not\n","try:\n","    ee.Initialize()\n","except Exception as e:\n","    ee.Authenticate()\n","    ee.Initialize()"]},{"cell_type":"markdown","id":"V5oDS0Rb0yED","metadata":{"id":"V5oDS0Rb0yED"},"source":["----> Only Run the next cell if wanting to export the generated pacthes to Google Cloud Storage.\n","\n","---\n","Please authenticate Google Cloud Storage as done above with Google Drive and Earth Engine"]},{"cell_type":"code","execution_count":null,"id":"uzhlG3Wv0x09","metadata":{"id":"uzhlG3Wv0x09"},"outputs":[],"source":["# Authorising Google Colab notebook to access the target Google Cloud account\n","auth.authenticate_user()"]},{"cell_type":"markdown","id":"LHx9MdOFyGBw","metadata":{"id":"LHx9MdOFyGBw"},"source":["# 2. Generating image composites\n","In this section Google Earth Engine Python API is used to generate image composites for a target year and geographical area, using pre-created regions of interests.\n","\n","\n"]},{"cell_type":"markdown","id":"6mMIa4EbyL_x","metadata":{"id":"6mMIa4EbyL_x"},"source":["## Loading necessary FeatureCollections\n","\n","This project uses the mangroves classification baselines generated by Worthington *et al.* (2020). <br/>\n","These can be found here: https://data.unep-wcmc.org/datasets/48\n","\n","---\n","The four large shapefiles were imported into Google Earth Engine as assets here: \n","* 1996 - https://code.earthengine.google.com/?asset=users/davidelomeo/lomeo_and_singh_2022/mangrove_typology_1996\n","* 2007 - https://code.earthengine.google.com/?asset=users/davidelomeo/lomeo_and_singh_2022/mangrove_typology_2007\n","* 2010 - https://code.earthengine.google.com/?asset=users/davidelomeo/lomeo_and_singh_2022/mangrove_typology_2010\n","* 2016 - https://code.earthengine.google.com/?asset=users/davidelomeo/lomeo_and_singh_2022/mangrove_typology_2016\n","\n","---\n","The target geographical area (i.e., Southeast Asia) was defined with the Earth Engine drawing tool and exported as an assset here:\n","* https://code.earthengine.google.com/?asset=users/davidelomeo/lomeo_and_singh_2022/SEA\n","\n","---\n","For the purposes of classifying land cover types in the target geographical area, 120 markers for each of the idntified 9 classes were manually generated using the Earth Engine online drawing tool and exported as an asset here: \n","* https://code.earthengine.google.com/?asset=users/davidelomeo/lomeo_and_singh_2022/mangrove_custom_classes_2016\n","\n","The markers were generated and exported using the JavaScript code here: \n","* https://code.earthengine.google.com/6ef129f21d8920c45f22d14a8ddc4eb3.\n","\n","The identified classes are:\n","* Mangroves -> Delta, Estuary, Lagoon, OpenCoast\n","* Water\n","* NonMangroves\n","* Clouds\n","* Ground\n","* Urban\n","\n","---\n","Becuase the geographical area was too large to export single patches for its entirety, it was decided to choose 3 small sample areas for the export of the pactehs. The thre areas were converted to an asset that can be found here:\n","* https://code.earthengine.google.com/?asset=users/davidelomeo/lomeo_and_singh_2022/export_patches_regions_2016_3_squares\n","\n","The target areas generates 48786 pacthes if setting patch-size to 256x256 pixels."]},{"cell_type":"code","execution_count":4,"id":"RN7PxT0b3aYW","metadata":{"executionInfo":{"elapsed":231,"status":"ok","timestamp":1629653662968,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"RN7PxT0b3aYW"},"outputs":[],"source":["# Manually classified markers\n","classes_2016 = ee.FeatureCollection(\n","    'users/davidelomeo/lomeo_and_singh_2022/mangrove_custom_classes_2016')\n","\n","# Loading a pre-defined Southeast Asia area of interest. This variable is not\n","# necessary but useful for delimiting the geographical area to Southeas Asia.\n","ROI = ee.FeatureCollection('users/davidelomeo/lomeo_and_singh_2022/SEA')\n","\n","# Loading pre-drawned small sample areas for patch export.\n","patches_regions = ee.FeatureCollection(\n","    'users/davidelomeo/lomeo_and_singh_2022/export_patches_regions_2016_3_squares') #Maybe need changing to 2_squares"]},{"cell_type":"markdown","id":"UdoHSn3zyQGv","metadata":{"id":"UdoHSn3zyQGv"},"source":["## Setup custom variables\n","Please modify these variables according to own needs and research"]},{"cell_type":"code","execution_count":5,"id":"nKUZ0IxNYWlJ","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1629653663670,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"nKUZ0IxNYWlJ"},"outputs":[],"source":["# Setting the start and end dates\n","start_date = ee.Date.fromYMD(2016, 1, 1)\n","end_date = ee.Date.fromYMD(2016, 12, 31)\n","\n","class_columns_name = 'Class'\n","\n","# Selecting the bands needed for the classification\n","bands = [\n","    'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', \n","    'NDVI', 'NDWI', 'MNDWI', 'NDSI', 'NDMI', 'EVI', 'EVI2', 'GOSAVI', 'SAVI'\n","]"]},{"cell_type":"markdown","id":"_Tw_Y5FRw5J8","metadata":{"id":"_Tw_Y5FRw5J8"},"source":["## Creation of buffers\n","Snippet of code to generate buffers around the points in the FeatureCollection `classes_2016`. The procedure is done to get more pixels for the classification.\n","\n","**Update**: although 9 classes were originally generated, later classification using deep neural networks suggested that the model was struggling to classify certain classes. It was decided to reduce the classes to 7 by merging Clouds, Ground and Urban classes."]},{"cell_type":"code","execution_count":null,"id":"RYXCHVP_ZCf2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1147,"status":"ok","timestamp":1629653673529,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"RYXCHVP_ZCf2","outputId":"d9159fdd-65b7-4801-eea2-19ae255e6cd1"},"outputs":[],"source":["# Separating clouds classes and creating small 5 meters buffers. This was done\n","# because clouds can be seen as very small from the satellite and could not risk\n","# to capture any of the pixels that did not belong to clouds\n","clouds = classes_2016.filter(\n","    ee.Filter.eq(class_columns_name, 6)).map(ct.buffer_size(5))\n","\n","# Creating 50m buffers around no-cloud classes points\n","no_clouds = classes_2016.filter(\n","    ee.Filter.neq(class_columns_name, 6)).map(ct.buffer_size(50))\n","\n","# Merging clouds with no_clouds classes and remapping classes Clouds, Urban\n","# and Ground so that they are classified as being the same (i.e., other)\n","region_of_interest = no_clouds.merge(clouds).remap([0, 1, 2, 3, 4, 5, 6, 7, 8],\n","                                                   [0, 1, 2, 3, 4, 5, 6, 6, 6],\n","                                                   'Class')\n","\n","# Checking classes points count\n","print('Clouds points count:', clouds.size().getInfo())\n","print('noClouds points count:', no_clouds.size().getInfo())\n","print('Total points count:', region_of_interest.size().getInfo())\n","\n","# Defining the name of the classes\n","classes_names = ['Delta', 'Estuary', 'Lagoon', 'OpenCoast', 'Water', 'NonMangroves', 'Other']"]},{"cell_type":"markdown","id":"-syu3r2pxbZ0","metadata":{"id":"-syu3r2pxbZ0"},"source":["## Loading images of the target year"]},{"cell_type":"code","execution_count":7,"id":"EHsQoXwYtuaU","metadata":{"executionInfo":{"elapsed":212,"status":"ok","timestamp":1629653675569,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"EHsQoXwYtuaU"},"outputs":[],"source":["# Loading the images for the selected period and bouding them to the target ROI.\n","# The images are pre-filtered to only get those with maximum 30% of cloud cover\n","# to reduce the cloud masking effect on the images.\n","image_collection = ee.ImageCollection('COPERNICUS/S2') \\\n","                     .filterDate(start_date, end_date) \\\n","                     .filterBounds(ROI) \\\n","                     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n","                     .map(ct.mask_sentinel_clouds)\n","\n","# Getting spectral indices for the median image and clipping to ROI. The median\n","# pixel value was preferred from the mean to avoid potential skeweness in the \n","# pixels values distribution\n","median_image = ct.sentinel2_spectral_indices(\n","    image_collection.median()).clip(ROI)\n","\n","# Creating a separate image for RGB visualisation\n","rgb_image = median_image.select(['B2', 'B3', 'B4'])\n","\n","# Adding the computed bands to the median image\n","median_image = median_image.select(bands)"]},{"cell_type":"markdown","id":"NSUQ227qwwWz","metadata":{"id":"NSUQ227qwwWz"},"source":["# 3. Classification of the image composite\n","In this section the median image was classified to obtain labelled images and later export them as patches ready for neural networks."]},{"cell_type":"markdown","id":"TaDYhuM6wkTy","metadata":{"id":"TaDYhuM6wkTy"},"source":["## Image Segmentation\n","The image was segmented using Simple Non-Iterative Clusteringto help the Random Forest classifier to better distinguish between land cover types."]},{"cell_type":"code","execution_count":8,"id":"0MX27Ev6wbk9","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1629653678391,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"0MX27Ev6wbk9"},"outputs":[],"source":["segmented_image = ct.segment_image(median_image, bands)"]},{"cell_type":"markdown","id":"Axmkg6AUR2Rd","metadata":{"id":"Axmkg6AUR2Rd"},"source":["## Splitting the data and generate the classifier\n","The data was split into training and test set using a 70-30 split. The classifier was then generated using the training set."]},{"cell_type":"code","execution_count":9,"id":"u-3sbX6eJUL6","metadata":{"executionInfo":{"elapsed":231,"status":"ok","timestamp":1629653680796,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"u-3sbX6eJUL6"},"outputs":[],"source":["# Reducing the segmented image to the input collection\n","training = segmented_image.sampleRegions(\n","  collection=region_of_interest, \n","  properties=[class_columns_name], \n","  scale=10)\n","\n","# Initialising random splitting adding a column of pseudo-random \n","# numbers between 0 and 1 to the collection\n","random_column = training.randomColumn('random')\n","\n","# Splitting the dataset into training and test datasets using the custom\n","# percentage.\n","train_dataset = random_column.filter(ee.Filter.lt('random', 0.7))\n","test_dataset = random_column.filter(ee.Filter.gte('random', 0.7))\n","\n","# Checking the sizes of the datasets\n","# print('Train Dataset size:', train_dataset.size().getInfo()) \n","# print('Test Dataset size:', test_dataset.size().getInfo())\n","\n","# Generating the classifier using random forest\n","classifier = ee.Classifier.smileRandomForest(\n","  numberOfTrees=200,\n",").train(\n","  features=train_dataset,\n","  classProperty=class_columns_name,\n","  inputProperties=median_image.bandNames())"]},{"cell_type":"markdown","id":"gdDJpp5hN8hl","metadata":{"id":"gdDJpp5hN8hl"},"source":["### Checking the accuracy of the classification (optional)\n","In the custom library created for this project, the package `get_metrics` allows to explore the result/ accuracy of the classification.\n","\n","One of the downside of using the Python API (especially on Google Colab) is that if the user wants to get numerical values from the Google Server, it is necessary to request them using the method `.getInfo()` which may be very slow (depending on the machine's internet speed and how busy the server is at that time).\n","\n","For this reason, it is adviced to only use `get_metrics` with caution. To prevent unwanted long runtimes, the package will only return the error matrix by default. This action alone may take up to 5 minutes to run.\n","\n","If all the available metrics are run at the same time (please see package documentation), the following line of code may take up to 15 minutes to run."]},{"cell_type":"code","execution_count":null,"id":"kCGLsj3RU_Ac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122103,"status":"ok","timestamp":1627467028931,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-60},"id":"kCGLsj3RU_Ac","outputId":"c7b49ae4-efc9-470d-d0f4-1bc0067e8f64"},"outputs":[],"source":["metrics = ct.get_metrics(classifier, test_dataset, class_columns_name)\n","pprint(metrics)"]},{"cell_type":"markdown","id":"945CfUqmYuJS","metadata":{"id":"945CfUqmYuJS"},"source":["## Classify the image using the custom classifier"]},{"cell_type":"code","execution_count":10,"id":"pzVRcrfSyZUK","metadata":{"executionInfo":{"elapsed":302,"status":"ok","timestamp":1629653684548,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"pzVRcrfSyZUK"},"outputs":[],"source":["# Assigning the name of the labels\n","classes_label = 'classes'\n","\n","# Classifying the target median image\n","classified_image = median_image.classify(classifier).rename(classes_label)"]},{"cell_type":"markdown","id":"jPoXP4sUVXZl","metadata":{"id":"jPoXP4sUVXZl"},"source":["# 4. Outputting the image and the classification"]},{"cell_type":"code","execution_count":null,"id":"Uc4w4f8O45cn","metadata":{"cellView":"code","colab":{"base_uri":"https://localhost:8080/","height":952},"executionInfo":{"elapsed":102696,"status":"ok","timestamp":1629653788948,"user":{"displayName":"Davide Lomeo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWsZLbvtgezThoXj2b1tjFJ0wYO7a6DEWpVUWiVQ=s64","userId":"00476587349921876723"},"user_tz":-120},"id":"Uc4w4f8O45cn","outputId":"c4ce4f2a-aabd-49f9-d29e-926ffcc86366"},"outputs":[],"source":["# Creating colour palette for the target classes\n","legend_dict = {\n","    'Delta': '80D604', \n","    'Estuary': '01BD7C', \n","    'Lagoon': '36DFFF', \n","    'OpenCoast': 'DEFF00', \n","    'Water': '0050D5', \n","    'NonMangroves': '106703', \n","    'Other': 'B06F03'\n","}\n","\n","# Creating a True Colour Composite image\n","RGB = {\n","  'min': 0.0,\n","  'max': 0.3,\n","  'bands': ['B4', 'B3', 'B2']}\n","\n","# Generating the map and adding layers for every feature that needs output\n","Map = geemap.Map(center=(7.8, -261), zoom=5, lite_mode=False)\n","\n","# True colour composite image\n","Map.addLayer(rgb_image, RGB, 'RGB Image')\n","\n","# Classified Image\n","Map.addLayer(classified_image, \n","             {'min': 0, 'max': 6, \n","              'palette': [v for v in legend_dict.values()]},\n","              'Classification 2016')\n","\n","# Legend\n","Map.add_legend(title='Legend', legend_dict=legend_dict)\n","\n","# Export regions\n","Map.addLayer(patches_regions, {}, 'Patches export regions', opacity=0.5)\n","\n","Map.centerObject(patches_regions, 8)\n","Map"]},{"cell_type":"markdown","id":"suF2jwcazeze","metadata":{"id":"suF2jwcazeze"},"source":["# 5. Prepare images for export in pathces\n","This section allows the user to generate pacthes of custom size within the pre-define `patches_regions` areas.\n","\n"]},{"cell_type":"markdown","id":"fcBZbTJ-ztlb","metadata":{"id":"fcBZbTJ-ztlb"},"source":["## Setting export parameters\n","The notebook is setup to save to Google Drive but the user can alternatively save to Google Cloud Storage."]},{"cell_type":"code","execution_count":null,"id":"sHA2jjgxiYdJ","metadata":{"id":"sHA2jjgxiYdJ"},"outputs":[],"source":["# Parameters needed for saving the pacthes in Google Drive.\n","pixels = 256\n","year = 2016\n","scale = 10\n","region = patches_regions\n","folder = 'Labelled_dataset_' + str(year) + '_' + str(pixels) + 'x' + str(pixels) + '_classes_7_48786'\n","prefix = 'record_' + str(pixels) + 'x' + str(pixels) + '-'\n","updated_bands = bands + [classes_label]\n","\n","# Image needed for the export\n","export_image = median_image.addBands(classified_image).select(updated_bands)"]},{"cell_type":"markdown","id":"WXqQq6T_zxMT","metadata":{"id":"WXqQq6T_zxMT"},"source":["## Saving parameters into a .json file\n","Collecting the general info about the exported pacthes to a .json file for later access"]},{"cell_type":"code","execution_count":null,"id":"KkhI01jZlSxp","metadata":{"id":"KkhI01jZlSxp"},"outputs":[],"source":["patches_info = {\n","    'pixels': pixels,\n","    'year': year,\n","    'folder': folder,\n","    'prefix': prefix,\n","    'bands': bands,\n","    'classes_label': classes_label,\n","    'classes': classes_names\n","     }\n","\n","# Exporting the .json file to Google Drive\n","path_to_json = '/content/drive/MyDrive/' + folder + '_export_pacthes_info.js'\n","with open(path_to_json, 'w') as f:\n","    json.dump(patches_info, f)"]},{"cell_type":"markdown","id":"KCHQb5_Pz10i","metadata":{"id":"KCHQb5_Pz10i"},"source":["## Export patches to the target cloud storage\n","The choice for this project was to use Google Drive as much as possible to reduce runnning costs, but the user may choose to save the pacthes to Google Cloud Storage using the commented snippet of code below instead."]},{"cell_type":"code","execution_count":null,"id":"fWC_wdo-iDmi","metadata":{"id":"fWC_wdo-iDmi"},"outputs":[],"source":["# Specify patch and file dimensions.\n","export_options = {\n","  'patchDimensions': [pixels, pixels],\n","  'compressed': True\n","}\n","\n","# Exporting patches to Google Drive\n","image_task = ee.batch.Export.image.toDrive(\n","  image = export_image,\n","  description = 'Patches_Export',\n","  folder = folder,\n","  fileNamePrefix = prefix,\n","  scale = scale,\n","  maxPixels = 3784216672400,\n","  fileFormat = 'TFRecord',\n","  region = region.geometry(),\n","  formatOptions = export_options,\n",")\n","\n","# # Exporting patches to Google Cloud Storage\n","# image_task = ee.batch.Export.image.toCloudStorage(\n","#   image = image,\n","#   description = 'Patches_Export',\n","#   fileNamePrefix = prefix,\n","#   bucket = 'define-the-google-storage-bucket-here',\n","#   scale = scale,\n","#   maxPixels = 3784216672400,\n","#   fileFormat = 'TFRecord',\n","#   region = region.geometry(),\n","#   formatOptions = export_options,\n","# )\n","\n","# Starting the export\n","image_task.start()"]},{"cell_type":"markdown","id":"6PMoj8U-PiKQ","metadata":{"id":"6PMoj8U-PiKQ"},"source":["### Monitoring export status (optional)\n","If running this cell, the code will run as long as the export tasks runs"]},{"cell_type":"code","execution_count":null,"id":"yMqvJ6gjiDYe","metadata":{"id":"yMqvJ6gjiDYe"},"outputs":[],"source":["# Checking the status of the export\n","while image_task.active():\n","  print('Running id: {}.'.format(image_task.id))\n","  time.sleep(120)"]},{"cell_type":"markdown","id":"DCfbJD4r4HCB","metadata":{"id":"DCfbJD4r4HCB"},"source":["# 6. Access Notebook 2 to generate the Neural Network model\n","\n","<table class=\"ee-notebook-buttons\" align=\"left\">\n","    <td><a target=\"_blank\"  href=\"https://github.com/davidelomeo/mangroves_deep_learning/blob/main/Notebook_2-Generate_Model.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> Access Notebook_2 on Github</a></td>\n","    <td><a target=\"_blank\"  href=\"https://colab.research.google.com/github.com/davidelomeo/mangroves_deep_learning/blob/main/Notebook_2-Generate_Model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run Notebook_2 in Google Colab</a></td>\n","</table>\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Notebook_1-Generate_Patches.ipynb","provenance":[{"file_id":"https://github.com/acse-2020/acse2020-acse9-finalreport-acse-dl1420-3/blob/main/main_notebook.ipynb","timestamp":1623835532107}]},"kernelspec":{"display_name":"Python 3.8 (work)","language":"python","name":"work"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}
